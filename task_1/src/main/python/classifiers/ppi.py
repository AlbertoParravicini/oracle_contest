#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Dec  4 14:41:33 2018

@author: aparravi
"""

import pandas as pd
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import KFold, cross_val_score
import random 
from sklearn.linear_model import SGDClassifier
import numpy as np
from sklearn.metrics import accuracy_score, f1_score
import datetime

def hamming_accuracy(prediction, true_values):
    """
    Metric used in multioutput-label classification,
    for each example measures the % of correctly predicted labels.
    
    Equivalent to traditional accuracy in a single-output scenario;
    """
    return np.sum(np.equal(prediction, true_values)) / float(true_values.size)


def get_score(prediction, true_values):    
    print("\tHamming accuracy: {:.3f}".format(hamming_accuracy(prediction, true_values)))
    print("\tAccuracy, exact matches: {:.3f}".format(accuracy_score(prediction, true_values)))
    print("\tMacro F1 Score: {:.3f}".format(f1_score(y_true=true_values, y_pred=prediction, average="macro")))
    print("\tMicro F1 Score: {:.3f}".format(f1_score(y_true=true_values, y_pred=prediction, average="micro")))
    

def build_dataframe(input_data: pd.DataFrame, col_name: str) -> pd.DataFrame:
    """
    Given an input DataFrame and a column name, return a new DataFrame in which the column has been cleaned.
    Used to transform features and labels columns from "0;1;1;0" to [0, 1, 1, 0]
    """
    vertices_dict = []
    for i, row_i in input_data.iterrows():
        features = [int(float(x)) for x in row_i[f"{col_name}s"].split(";")]
        
        new_v = {"id": i}
        for j, f in enumerate(features):
            new_v[f"{col_name}_{j}"] = f
        vertices_dict += [new_v]
    res_df = pd.DataFrame(vertices_dict)
    return res_df.set_index("id")


def bool_to_int(labels: list) -> list:
    """
    Turn a list of 0s and 1s into a list whose values are the indices of 1s.
    Used to create a valid Kaggle submission.
    E.g. [1, 0, 0, 1, 1] -> [0, 3, 4]
    """
    return [i for i, x in enumerate(labels) if x == 1]


#%%

if __name__ == "__main__":
    
    graph_name = "ppi"
    
    # Load the embeddings;
    embeddings_path = f"../../../../data/pgx-graphs/{graph_name}/embeddings.csv"
    embeddings_df = pd.read_csv(embeddings_path, header=None, index_col=0)
    embeddings_df.columns = ["e_" + str(col) for col in embeddings_df.columns]

    # Read vertex features and classes in the training set;
    vertices_path = f"../../../../data/pgx-graphs/{graph_name}/{graph_name}_train.csv"
    vertices_train = pd.read_csv(vertices_path, sep=",", index_col="id")
    vertices_train["dataset"] = "train"
    
    # Read vertex features in the test/validation set;
    vertices_path = f"../../../../data/pgx-graphs/{graph_name}/{graph_name}_test.csv"
    vertices_test = pd.read_csv(vertices_path, sep=",", index_col="id")
    vertices_test["dataset"] = "test"
        
    # Use a temporary dict representation to turn training set features into independent columns;
    X_train_df = build_dataframe(vertices_train, "feature")
    
    # Do the same for the test set;
    X_test_df = build_dataframe(vertices_test, "feature")
    
    # Create a dataset with the labels of the training set;
    y_train_df = build_dataframe(vertices_train, "label")
    
    
    #%% Add each vertex embedding to the vertices df;
    X_train_df = pd.merge(X_train_df, embeddings_df, left_index=True, right_index=True, how="left")
    X_test_df = pd.merge(X_test_df, embeddings_df, left_index=True, right_index=True, how="left")
    
   
    #%% Create a classifier for the problem;
    
    # Define crossvalidation.
    # Note that we are not using the test set when doing crossvalidation,
    #  as test sets are generated by crossvalidation itself.
    # We can also use the test set instead of crossvalidation, but the accuracy estimation is usually worse;
    kfolds = KFold(n_splits=3)
    
    seed = random.randint(0, 2**32)
    
    sgd = SGDClassifier(max_iter=10)
    model = OneVsRestClassifier(sgd, n_jobs=1)
    
    # Test with crossvalidation the specified model;
    scores = cross_val_score(model, X_train_df, y_train_df, cv=kfolds, n_jobs=2, verbose=2, scoring="f1_macro")
    print(f"Scores: {np.mean(scores):.3f}")
    
    
    #%% Train on the entire training set;
    
    model.fit(X_train_df, y_train_df)
    
    # Printing train scores (look for overfitting!);
    print("Train accuracy")
    y_train_pred = model.predict(X_train_df)
    get_score(y_train_pred, y_train_df)
    
    # Predict on the test dataset;
    print("\nValidation accuracy")
    y_test_pred = model.predict(X_test_df)
    
    
    #%% Store the predictions in a file;
    
    y_pred = [" ".join([str(y) for y in bool_to_int(x)]) for x in y_test_pred]
    y_pred_df = pd.DataFrame(y_pred, columns=["labels"], index=X_test_df.index)
    y_pred_df.to_csv(f"prediction_{datetime.datetime.now().strftime('%y_%m_%d_%H_%M_%S')}.csv")
    
    
    
    
    
    
    
    